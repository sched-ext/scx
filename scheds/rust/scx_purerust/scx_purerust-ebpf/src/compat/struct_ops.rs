//! sched_ext struct_ops boilerplate: type definitions and the
//! `scx_ops_define!` registration macro.
//!
//! HACK: All of this should be auto-generated by an aya struct_ops
//! procedural macro. The `scx_ops_define!` macro generates:
//!
//! 1. Callback trampolines that extract arguments from the BPF context
//!    pointer and forward them to the scheduler's clean callback functions.
//! 2. The `sched_ext_ops` static in `.struct_ops.link` for libbpf to
//!    auto-attach.
//!
//! The `sched_ext_ops` struct field names must match kernel BTF exactly.
//! Field types don't matter — the userspace BTF patcher replaces all
//! function pointer field types with PTR -> FUNC_PROTO.

// ── Callback type aliases ───────────────────────────────────────────────
//
// Generic function pointer types for struct field declarations. The
// actual signatures don't matter for BTF (they get patched), but they
// must be pointer-sized so Option<T> uses null-pointer optimization.

type VoidCb = unsafe extern "C" fn(*const u64);
type I32Cb = unsafe extern "C" fn(*const u64) -> i32;
type InitCb = unsafe extern "C" fn() -> i32;

// ── sched_ext_ops ───────────────────────────────────────────────────────

/// Kernel `struct sched_ext_ops` — 34 callback fields + 6 data fields.
#[repr(C)]
pub struct sched_ext_ops {
    pub select_cpu: Option<I32Cb>,
    pub enqueue: Option<VoidCb>,
    pub dequeue: Option<VoidCb>,
    pub dispatch: Option<VoidCb>,
    pub tick: Option<VoidCb>,
    pub runnable: Option<VoidCb>,
    pub running: Option<VoidCb>,
    pub stopping: Option<VoidCb>,
    pub quiescent: Option<VoidCb>,
    pub r#yield: Option<VoidCb>,
    pub core_sched_before: Option<VoidCb>,
    pub set_weight: Option<VoidCb>,
    pub set_cpumask: Option<VoidCb>,
    pub update_idle: Option<VoidCb>,
    pub cpu_acquire: Option<VoidCb>,
    pub cpu_release: Option<VoidCb>,
    pub init_task: Option<I32Cb>,
    pub exit_task: Option<VoidCb>,
    pub enable: Option<VoidCb>,
    pub disable: Option<VoidCb>,
    pub dump: Option<VoidCb>,
    pub dump_cpu: Option<VoidCb>,
    pub dump_task: Option<VoidCb>,
    pub cgroup_init: Option<I32Cb>,
    pub cgroup_exit: Option<VoidCb>,
    pub cgroup_prep_move: Option<I32Cb>,
    pub cgroup_move: Option<VoidCb>,
    pub cgroup_cancel_move: Option<VoidCb>,
    pub cgroup_set_weight: Option<VoidCb>,
    pub cgroup_set_bandwidth: Option<VoidCb>,
    pub cpu_online: Option<VoidCb>,
    pub cpu_offline: Option<VoidCb>,
    pub init: Option<InitCb>,
    pub exit: Option<VoidCb>,
    // Data fields
    pub dispatch_max_batch: u32,
    pub flags: u64,
    pub timeout_ms: u32,
    pub exit_dump_len: u32,
    pub hotplug_seq: u64,
    pub name: [u8; 128],
}

/// All callbacks unset, all data fields zeroed.
pub const DEFAULT_OPS: sched_ext_ops = sched_ext_ops {
    select_cpu: None,
    enqueue: None,
    dequeue: None,
    dispatch: None,
    tick: None,
    runnable: None,
    running: None,
    stopping: None,
    quiescent: None,
    r#yield: None,
    core_sched_before: None,
    set_weight: None,
    set_cpumask: None,
    update_idle: None,
    cpu_acquire: None,
    cpu_release: None,
    init_task: None,
    exit_task: None,
    enable: None,
    disable: None,
    dump: None,
    dump_cpu: None,
    dump_task: None,
    cgroup_init: None,
    cgroup_exit: None,
    cgroup_prep_move: None,
    cgroup_move: None,
    cgroup_cancel_move: None,
    cgroup_set_weight: None,
    cgroup_set_bandwidth: None,
    cpu_online: None,
    cpu_offline: None,
    init: None,
    exit: None,
    dispatch_max_batch: 0,
    flags: 0,
    timeout_ms: 0,
    exit_dump_len: 0,
    hotplug_seq: 0,
    name: [0u8; 128],
};

// ── scx_ops_define! macro ───────────────────────────────────────────────
//
// Analogous to the C `SCX_OPS_DEFINE` macro. The scheduler author lists
// their callbacks and the macro generates trampolines + the ops map.
//
// Usage:
//   scx_ops_define! {
//       name: "my_scheduler",
//       enqueue: my_enqueue_fn,
//       dispatch: my_dispatch_fn,
//       init: my_init_fn,
//       exit: my_exit_fn,
//   }

#[macro_export]
macro_rules! scx_ops_define {
    // ── Entry point ─────────────────────────────────────────────────────
    (name: $name:expr, $($field:ident : $handler:path),* $(,)?) => {
        // Generate a trampoline for each registered callback.
        $($crate::scx_ops_define!(@trampoline $field $handler);)*

        // Generate the ops static with `..DEFAULT_OPS` for unset fields.
        #[unsafe(link_section = ".struct_ops.link")]
        #[unsafe(no_mangle)]
        static _scx_ops: $crate::compat::struct_ops::sched_ext_ops =
            $crate::compat::struct_ops::sched_ext_ops {
                $($field: Some($field),)*
                name: {
                    let mut n = [0u8; 128];
                    let src = $name.as_bytes();
                    let mut i = 0;
                    while i < src.len() {
                        n[i] = src[i];
                        i += 1;
                    }
                    n
                },
                ..$crate::compat::struct_ops::DEFAULT_OPS
            };
    };

    // ── Trampoline generators ───────────────────────────────────────────
    //
    // Each arm knows the kernel callback signature and generates code to
    // extract arguments from the BPF context pointer (R1). The verifier
    // uses the *kernel* BTF to type-check ctx accesses, not our types.

    // select_cpu(task_struct *p, s32 prev_cpu, u64 wake_flags) -> s32
    (@trampoline select_cpu $handler:path) => {
        #[unsafe(no_mangle)]
        #[unsafe(link_section = "struct_ops/select_cpu")]
        unsafe extern "C" fn select_cpu(ctx: *const u64) -> i32 {
            let p = unsafe { *ctx as *mut $crate::compat::vmlinux::task_struct };
            let prev_cpu = unsafe { *ctx.add(1) as i32 };
            let wake_flags = unsafe { *ctx.add(2) };
            $handler(p, prev_cpu, wake_flags)
        }
    };

    // enqueue(task_struct *p, u64 enq_flags)
    (@trampoline enqueue $handler:path) => {
        #[unsafe(no_mangle)]
        #[unsafe(link_section = "struct_ops/enqueue")]
        unsafe extern "C" fn enqueue(ctx: *const u64) {
            let p = unsafe { *ctx as *mut $crate::compat::vmlinux::task_struct };
            let enq_flags = unsafe { *ctx.add(1) };
            $handler(p, enq_flags);
        }
    };

    // dequeue(task_struct *p, u64 deq_flags)
    (@trampoline dequeue $handler:path) => {
        #[unsafe(no_mangle)]
        #[unsafe(link_section = "struct_ops/dequeue")]
        unsafe extern "C" fn dequeue(ctx: *const u64) {
            let p = unsafe { *ctx as *mut $crate::compat::vmlinux::task_struct };
            let deq_flags = unsafe { *ctx.add(1) };
            $handler(p, deq_flags);
        }
    };

    // dispatch(s32 cpu, task_struct *prev)
    (@trampoline dispatch $handler:path) => {
        #[unsafe(no_mangle)]
        #[unsafe(link_section = "struct_ops/dispatch")]
        unsafe extern "C" fn dispatch(ctx: *const u64) {
            let cpu = unsafe { *ctx as i32 };
            let prev = unsafe { *ctx.add(1) as *mut $crate::compat::vmlinux::task_struct };
            $handler(cpu, prev);
        }
    };

    // running(task_struct *p)
    (@trampoline running $handler:path) => {
        #[unsafe(no_mangle)]
        #[unsafe(link_section = "struct_ops/running")]
        unsafe extern "C" fn running(ctx: *const u64) {
            let p = unsafe { *ctx as *mut $crate::compat::vmlinux::task_struct };
            $handler(p);
        }
    };

    // stopping(task_struct *p, bool runnable)
    (@trampoline stopping $handler:path) => {
        #[unsafe(no_mangle)]
        #[unsafe(link_section = "struct_ops/stopping")]
        unsafe extern "C" fn stopping(ctx: *const u64) {
            let p = unsafe { *ctx as *mut $crate::compat::vmlinux::task_struct };
            let runnable = unsafe { *ctx.add(1) != 0 };
            $handler(p, runnable);
        }
    };

    // enable(task_struct *p)
    (@trampoline enable $handler:path) => {
        #[unsafe(no_mangle)]
        #[unsafe(link_section = "struct_ops/enable")]
        unsafe extern "C" fn enable(ctx: *const u64) {
            let p = unsafe { *ctx as *mut $crate::compat::vmlinux::task_struct };
            $handler(p);
        }
    };

    // disable(task_struct *p)
    (@trampoline disable $handler:path) => {
        #[unsafe(no_mangle)]
        #[unsafe(link_section = "struct_ops/disable")]
        unsafe extern "C" fn disable(ctx: *const u64) {
            let p = unsafe { *ctx as *mut $crate::compat::vmlinux::task_struct };
            $handler(p);
        }
    };

    // init() -> s32  (sleepable)
    (@trampoline init $handler:path) => {
        #[unsafe(no_mangle)]
        #[unsafe(link_section = "struct_ops.s/init")]
        unsafe extern "C" fn init() -> i32 {
            $handler()
        }
    };

    // exit(scx_exit_info *ei)
    (@trampoline exit $handler:path) => {
        #[unsafe(no_mangle)]
        #[unsafe(link_section = "struct_ops/exit")]
        unsafe extern "C" fn exit(ctx: *const u64) {
            let ei = unsafe { *ctx as *mut $crate::compat::vmlinux::scx_exit_info };
            $handler(ei);
        }
    };

    // Catch-all: compile error for callbacks not yet supported
    (@trampoline $field:ident $handler:path) => {
        compile_error!(concat!(
            "Unsupported callback '",
            stringify!($field),
            "'. Add a trampoline arm to scx_ops_define! in compat/struct_ops.rs."
        ));
    };
}
